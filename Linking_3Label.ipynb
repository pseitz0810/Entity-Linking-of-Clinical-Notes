{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607beec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import dill as pickle\n",
    "from snomed_graph import *\n",
    "from sentence_transformers import InputExample, SentenceTransformer, losses, models, evaluation\n",
    "from itertools import combinations\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ffad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNOMED graph has 361179 vertices and 1179749 edges\n"
     ]
    }
   ],
   "source": [
    "SG = SnomedGraph.from_serialized('full_concept_graph.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a14a94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219172\n"
     ]
    }
   ],
   "source": [
    "procedures = SG.get_descendants(71388002)\n",
    "procedures.add(SG.get_concept_details(71388002))\n",
    "\n",
    "body_structures = SG.get_descendants(123037004)\n",
    "body_structures.add(SG.get_concept_details(123037004))\n",
    "\n",
    "clinical_finding = SG.get_descendants(404684003)\n",
    "clinical_finding.add(SG.get_concept_details(404684003))\n",
    "\n",
    "all_concepts = procedures.union(body_structures)\n",
    "all_concepts.update(clinical_finding)\n",
    "print(len(all_concepts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3178d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e94b27ee0f4675a32b368a32d89864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/219172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cce5f0184f476880d623f8d3f689f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b226ef26854831ad7d323bc8267640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309830f4a9f145cfaec66cf4de1b75ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/8586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#What is label=1?\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "kb_embedding_model_id = (\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "kb_model = SentenceTransformer(kb_embedding_model_id,device=device)\n",
    "# kb_model = kb_model.to(device)\n",
    "\n",
    "sentences1 = []\n",
    "sentences2 = []\n",
    "labels = []\n",
    "kb_sft_examples = []\n",
    "for concept in tqdm(all_concepts):\n",
    "    #Add synonym pairs\n",
    "    for syn1, syn2 in combinations(SG.get_concept_details(concept.sctid).synonyms, 2):\n",
    "        kb_sft_examples.append(InputExample(texts=[syn1, syn2], label=1))\n",
    "        sentences1.append(syn1)\n",
    "        sentences2.append(syn2)\n",
    "        labels.append(1)\n",
    "    \n",
    "    # #add parent pairs\n",
    "    # for p in SG.get_parents(concept.sctid):\n",
    "    #     kb_sft_examples.append(InputExample(texts=[p.fsn.split('(')[0], SG.get_concept_details(concept.sctid).fsn.split('(')[0]], label=1))\n",
    "\n",
    "    # #Add ancestor pairings\n",
    "    # for a in SG.get_ancestors(concept.sctid):\n",
    "    #     kb_sft_examples.append(InputExample(texts=[a.fsn.split('(')[0], SG.get_concept_details(concept.sctid).fsn.split('(')[0]], label=1))\n",
    "\n",
    "kb_sft_dataloader = DataLoader(kb_sft_examples, shuffle=True, batch_size=32)\n",
    "kb_sft_loss = losses.ContrastiveLoss(kb_model)\n",
    "\n",
    "kb_model.fit(\n",
    "    train_objectives=[(kb_sft_dataloader, kb_sft_loss)],\n",
    "    epochs=2,\n",
    ")\n",
    "\n",
    "# kb_model.save(\"kb_model_3label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e4cd9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_model = SentenceTransformer('kb_model_3label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221184e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linker:\n",
    "    def __init__(self, encoder, context_window_width=0):\n",
    "        self.encoder = encoder\n",
    "        self.entity_index = KeyedVectors(self.encoder[1].word_embedding_dimension)\n",
    "        self.context_index = dict()\n",
    "        self.history = dict()\n",
    "        self.context_window_width = context_window_width\n",
    "\n",
    "    def add_context(self, row):\n",
    "        window_start = max(0, row.start - self.context_window_width)\n",
    "        window_end = min(row.end + self.context_window_width, len(row.text))\n",
    "        return row.text[window_start:window_end]\n",
    "\n",
    "    def add_entity(self, row):\n",
    "        return row.text[row.start : row.end]\n",
    "\n",
    "    def fit(self, df=None, snomed_concepts=None):\n",
    "        # Create a map from the entities to the concepts and contexts in which they appear\n",
    "        if df is not None:\n",
    "            for row in df.itertuples():\n",
    "                entity = self.add_entity(row)\n",
    "                context = self.add_context(row)\n",
    "                map_ = self.history.get(entity, dict())\n",
    "                contexts = map_.get(row.concept_id, list())\n",
    "                contexts.append(context)\n",
    "                map_[row.concept_id] = contexts\n",
    "                self.history[entity] = map_\n",
    "\n",
    "        # Add SNOMED CT codes for lookup\n",
    "        if snomed_concepts is not None:\n",
    "            for c in snomed_concepts:\n",
    "                # for syn in c.synonyms:\n",
    "                for syn in SG.get_concept_details(c.sctid).synonyms:\n",
    "                    map_ = self.history.get(syn, dict())\n",
    "                    contexts = map_.get(c.sctid, list())\n",
    "                    contexts.append(syn)\n",
    "                    map_[c.sctid] = contexts\n",
    "                    self.history[syn] = map_\n",
    "\n",
    "        # Create indexes to help disambiguate entities by their contexts\n",
    "        for entity, map_ in tqdm(self.history.items()):\n",
    "            keys = [\n",
    "                (concept_id, occurance)\n",
    "                for concept_id, contexts in map_.items()\n",
    "                for occurance, context in enumerate(contexts)\n",
    "            ]\n",
    "            contexts = [context for contexts in map_.values() for context in contexts]\n",
    "            vectors = self.encoder.encode(contexts)\n",
    "            index = KeyedVectors(self.encoder[1].word_embedding_dimension)\n",
    "            index.add_vectors(keys, vectors)\n",
    "            self.context_index[entity] = index\n",
    "\n",
    "        # Now create the top-level entity index\n",
    "        keys = list(self.history.keys())\n",
    "        vectors = self.encoder.encode(keys)\n",
    "        self.entity_index.add_vectors(keys, vectors)\n",
    "\n",
    "    def link(self, row):\n",
    "        entity = self.add_entity(row)\n",
    "        context = self.add_context(row)\n",
    "        vec = self.encoder.encode(entity)\n",
    "        #Map to known entity\n",
    "        nearest_entity = self.entity_index.most_similar(vec, topn=1)[0][0]\n",
    "        index = self.context_index.get(nearest_entity, None)\n",
    "\n",
    "        #When would it ever not return index? If nearest_entity not found in train set?\n",
    "        if index:\n",
    "            vec = self.encoder.encode(context)\n",
    "            #Within givin known entity, if multiple SCTIDs associated, then get SCTID with closest context\n",
    "            key, score = index.most_similar(vec, topn=1)[0]\n",
    "            sctid, _ = key\n",
    "            return sctid\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6770eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train notes: 184 : # of Annotations: (46955, 4)\n"
     ]
    }
   ],
   "source": [
    "all_notes = pd.read_csv('mimic-iv_notes_training_set.csv',index_col='note_id')\n",
    "all_annotations = pd.read_csv('train_annotations.csv',index_col='note_id')\n",
    "\n",
    "rng = np.random.default_rng(seed=42)\n",
    "shuffled_indices = rng.permutation(len(all_notes))\n",
    "\n",
    "train_notes = all_notes.iloc[shuffled_indices[:184],:] #~90%\n",
    "train_notes_with_annotations = pd.merge(left=train_notes,right=all_annotations,how='left',left_index=True,right_index=True)\n",
    "\n",
    "print('Train notes:',len(train_notes),': # of Annotations:',train_notes_with_annotations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc67c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_training_df = train_notes_with_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e9a8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8365dacd8e674b2d9e006120da297816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/385329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linker = Linker(kb_model, 12)\n",
    "linker.fit(linker_training_df, all_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df7a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3label_linker.pickle\", \"wb\") as f:\n",
    "    pickle.dump(linker, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"3label_linker.pickle\", \"rb\") as f:\n",
    "#     linker = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc6c93ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c02eb7bd24e404a8f6ac8b0be3cabf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>concept_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14652764-DS-17</td>\n",
       "      <td>178</td>\n",
       "      <td>186</td>\n",
       "      <td>281900007</td>\n",
       "      <td>\\nName:  ___                 Unit No:   ___\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14652764-DS-17</td>\n",
       "      <td>199</td>\n",
       "      <td>221</td>\n",
       "      <td>419511003</td>\n",
       "      <td>\\nName:  ___                 Unit No:   ___\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14652764-DS-17</td>\n",
       "      <td>259</td>\n",
       "      <td>277</td>\n",
       "      <td>64766004</td>\n",
       "      <td>\\nName:  ___                 Unit No:   ___\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14652764-DS-17</td>\n",
       "      <td>322</td>\n",
       "      <td>340</td>\n",
       "      <td>47092002</td>\n",
       "      <td>\\nName:  ___                 Unit No:   ___\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14652764-DS-17</td>\n",
       "      <td>406</td>\n",
       "      <td>425</td>\n",
       "      <td>26925005</td>\n",
       "      <td>\\nName:  ___                 Unit No:   ___\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>15906604-DS-2</td>\n",
       "      <td>5421</td>\n",
       "      <td>5428</td>\n",
       "      <td>71616004</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>15906604-DS-2</td>\n",
       "      <td>5433</td>\n",
       "      <td>5442</td>\n",
       "      <td>4303006</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>15906604-DS-2</td>\n",
       "      <td>5480</td>\n",
       "      <td>5484</td>\n",
       "      <td>22253000</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>15906604-DS-2</td>\n",
       "      <td>5511</td>\n",
       "      <td>5523</td>\n",
       "      <td>103622007</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>15906604-DS-2</td>\n",
       "      <td>5544</td>\n",
       "      <td>5551</td>\n",
       "      <td>401207004</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2180 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             note_id start   end concept_id  \\\n",
       "0     14652764-DS-17   178   186  281900007   \n",
       "1     14652764-DS-17   199   221  419511003   \n",
       "2     14652764-DS-17   259   277   64766004   \n",
       "3     14652764-DS-17   322   340   47092002   \n",
       "4     14652764-DS-17   406   425   26925005   \n",
       "...              ...   ...   ...        ...   \n",
       "2175   15906604-DS-2  5421  5428   71616004   \n",
       "2176   15906604-DS-2  5433  5442    4303006   \n",
       "2177   15906604-DS-2  5480  5484   22253000   \n",
       "2178   15906604-DS-2  5511  5523  103622007   \n",
       "2179   15906604-DS-2  5544  5551  401207004   \n",
       "\n",
       "                                                   text  \n",
       "0      \\nName:  ___                 Unit No:   ___\\n...  \n",
       "1      \\nName:  ___                 Unit No:   ___\\n...  \n",
       "2      \\nName:  ___                 Unit No:   ___\\n...  \n",
       "3      \\nName:  ___                 Unit No:   ___\\n...  \n",
       "4      \\nName:  ___                 Unit No:   ___\\n...  \n",
       "...                                                 ...  \n",
       "2175   \\nName:  ___                     Unit No:   _...  \n",
       "2176   \\nName:  ___                     Unit No:   _...  \n",
       "2177   \\nName:  ___                     Unit No:   _...  \n",
       "2178   \\nName:  ___                     Unit No:   _...  \n",
       "2179   \\nName:  ___                     Unit No:   _...  \n",
       "\n",
       "[2180 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('3label_pred.json') as f:\n",
    "    data = f.read()\n",
    "\n",
    "annotations_3label = json.loads(json.loads(data))\n",
    "\n",
    "df_3label = pd.DataFrame(columns=['note_id','start','end','concept_id'])\n",
    "for note in annotations_3label:\n",
    "    for annotation in annotations_3label[note]:\n",
    "        df_3label.loc[len(df_3label),:] = [note,list(annotation.values())[0][0],list(annotation.values())[0][1],-1]\n",
    "\n",
    "df_3label = pd.merge(left=df_3label,right=all_notes[['text']],how='left',left_on='note_id',right_index=True)\n",
    "\n",
    "for _,row in tqdm(df_3label.iterrows()):\n",
    "    df_3label.loc[_,'concept_id'] = linker.link(row)\n",
    "\n",
    "df_3label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ea25bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3label.set_index('note_id')[['start','end','concept_id']].to_csv('3label_res_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fccf5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['14652764-DS-17', '16441224-DS-19', '18914188-DS-20',\n",
       "       '10797747-DS-20', '16464652-DS-17', '19476699-DS-25',\n",
       "       '11436844-DS-4', '13397956-DS-5', '19442119-DS-15',\n",
       "       '15906604-DS-2'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3label['note_id'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pseitz_capstone_2",
   "language": "python",
   "name": "pseitz_capstone_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
